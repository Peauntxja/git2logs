#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GitLab æäº¤æ—¥å¿—ç”Ÿæˆå·¥å…·
ä» GitLab ä»“åº“è·å–æŒ‡å®šæäº¤è€…æ¯å¤©çš„ä»£ç æäº¤ï¼Œç”Ÿæˆç®€æ´çš„ Markdown æ ¼å¼æ—¥å¿—
"""
import argparse
import sys
import os
from datetime import datetime
from collections import defaultdict
from urllib.parse import urlparse
import logging

try:
    import gitlab  # pyright: ignore[reportMissingImports]
except ImportError:
    print("é”™è¯¯: æœªå®‰è£… python-gitlab åº“")
    print("è¯·è¿è¡Œ: pip install python-gitlab")
    sys.exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def create_gitlab_client(gitlab_url, token=None):
    """
    åˆ›å»º GitLab å®¢æˆ·ç«¯è¿æ¥
    
    Args:
        gitlab_url: GitLab å®ä¾‹ URLï¼ˆä¾‹å¦‚ï¼šhttps://gitlab.comï¼‰
        token: è®¿é—®ä»¤ç‰Œï¼ˆå¯é€‰ï¼Œç§æœ‰ä»“åº“éœ€è¦ï¼‰
    
    Returns:
        gitlab.Gitlab: GitLab å®¢æˆ·ç«¯å®ä¾‹
    """
    if not token:
        logger.warning("æœªæä¾›è®¿é—®ä»¤ç‰Œï¼Œå¯èƒ½æ— æ³•è®¿é—®ç§æœ‰ä»“åº“")
    
    try:
        gl = gitlab.Gitlab(gitlab_url, private_token=token)
        gl.auth()  # éªŒè¯è¿æ¥
        logger.info(f"æˆåŠŸè¿æ¥åˆ° GitLab å®ä¾‹: {gitlab_url}")
        return gl
    except Exception as e:
        logger.error(f"è¿æ¥ GitLab å¤±è´¥: {str(e)}")
        raise


def parse_project_identifier(repo_url):
    """
    ä»ä»“åº“ URL æˆ–è·¯å¾„è§£æé¡¹ç›®æ ‡è¯†ç¬¦
    
    æ”¯æŒçš„æ ¼å¼ï¼š
    - https://gitlab.com/group/project
    - https://gitlab.com/group/project.git
    - http://gitlab.example.com/group/project.git
    - group/project
    - group%2Fproject
    
    Args:
        repo_url: ä»“åº“ URL æˆ–è·¯å¾„
    
    Returns:
        str: é¡¹ç›®æ ‡è¯†ç¬¦ï¼ˆgroup/project æ ¼å¼ï¼‰
    """
    # å¦‚æœæ˜¯å®Œæ•´çš„ URL
    if repo_url.startswith('http://') or repo_url.startswith('https://'):
        parsed = urlparse(repo_url)
        path = parsed.path.strip('/')
        # ç§»é™¤ .git åç¼€
        if path.endswith('.git'):
            path = path[:-4]
        return path
    else:
        # ç›´æ¥æ˜¯è·¯å¾„æ ¼å¼
        return repo_url.strip('/')


def extract_gitlab_url(repo_url):
    """
    ä»ä»“åº“ URL ä¸­æå– GitLab å®ä¾‹ URL
    
    Args:
        repo_url: ä»“åº“ URL
    
    Returns:
        str: GitLab å®ä¾‹ URLï¼Œå¦‚æœä¸æ˜¯å®Œæ•´ URL åˆ™è¿”å› None
    """
    if repo_url.startswith('http://') or repo_url.startswith('https://'):
        parsed = urlparse(repo_url)
        return f"{parsed.scheme}://{parsed.netloc}"
    return None


def get_commits_by_author(project, author_name, since_date=None, until_date=None, branch=None):
    """
    è·å–æŒ‡å®šæäº¤è€…çš„æ‰€æœ‰æäº¤
    
    Args:
        project: GitLab é¡¹ç›®å¯¹è±¡
        author_name: æäº¤è€…å§“åæˆ–é‚®ç®±
        since_date: èµ·å§‹æ—¥æœŸï¼ˆå¯é€‰ï¼Œæ ¼å¼ï¼šYYYY-MM-DDï¼‰
        until_date: ç»“æŸæ—¥æœŸï¼ˆå¯é€‰ï¼Œæ ¼å¼ï¼šYYYY-MM-DDï¼‰
        branch: åˆ†æ”¯åç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤æŸ¥è¯¢æ‰€æœ‰åˆ†æ”¯ï¼‰
    
    Returns:
        list: æäº¤åˆ—è¡¨
    """
    if branch:
        logger.info(f"å¼€å§‹è·å–æäº¤è€… '{author_name}' åœ¨åˆ†æ”¯ '{branch}' çš„æäº¤è®°å½•...")
    else:
        logger.info(f"å¼€å§‹è·å–æäº¤è€… '{author_name}' çš„æäº¤è®°å½•...")
    
    commits = []
    page = 1
    per_page = 100
    
    # å¦‚æœæŒ‡å®šäº†åˆ†æ”¯ï¼Œç›´æ¥æŸ¥è¯¢è¯¥åˆ†æ”¯
    if branch:
        params = {
            'author': author_name,
            'ref_name': branch,
            'per_page': per_page
        }
        
        # æ·»åŠ æ—¥æœŸèŒƒå›´
        if since_date:
            params['since'] = f"{since_date}T00:00:00Z"
        if until_date:
            params['until'] = f"{until_date}T23:59:59Z"
        
        try:
            while True:
                params['page'] = page
                page_commits = project.commits.list(**params)
                
                if not page_commits:
                    break
                
                commits.extend(page_commits)
                logger.info(f"å·²è·å– {len(commits)} æ¡æäº¤è®°å½•...")
                
                if len(page_commits) < per_page:
                    break
                
                page += 1
            
            logger.info(f"å…±è·å–åˆ° {len(commits)} æ¡æäº¤è®°å½•")
            return commits
        except Exception as e:
            logger.error(f"è·å–æäº¤è®°å½•å¤±è´¥: {str(e)}")
            raise
    else:
        # ä¸æŒ‡å®šåˆ†æ”¯æ—¶ï¼Œéå†æ‰€æœ‰åˆ†æ”¯æŸ¥è¯¢
        # GitLab API çš„ all=True å‚æ•°å¯èƒ½æ— æ³•æ­£ç¡®æŒ‰ä½œè€…è¿‡æ»¤
        logger.info("æœªæŒ‡å®šåˆ†æ”¯ï¼Œå°†éå†æ‰€æœ‰åˆ†æ”¯æŸ¥è¯¢...")
        all_commits = []
        branches = project.branches.list(per_page=100)
        logger.info(f"æ‰¾åˆ° {len(branches)} ä¸ªåˆ†æ”¯ï¼Œå¼€å§‹éå†æŸ¥è¯¢...")
        
        for idx, branch_obj in enumerate(branches, 1):
            try:
                branch_params = {
                    'author': author_name,
                    'ref_name': branch_obj.name,
                    'per_page': per_page
                }
                
                if since_date:
                    branch_params['since'] = f"{since_date}T00:00:00Z"
                if until_date:
                    branch_params['until'] = f"{until_date}T23:59:59Z"
                
                branch_commits = []
                branch_page = 1
                while True:
                    branch_params['page'] = branch_page
                    page_commits = project.commits.list(**branch_params)
                    
                    if not page_commits:
                        break
                    
                    branch_commits.extend(page_commits)
                    
                    if len(page_commits) < per_page:
                        break
                    
                    branch_page += 1
                
                if branch_commits:
                    logger.info(f"[{idx}/{len(branches)}] åˆ†æ”¯ '{branch_obj.name}': æ‰¾åˆ° {len(branch_commits)} æ¡æäº¤")
                    all_commits.extend(branch_commits)
            except Exception as e:
                # å¿½ç•¥æƒé™ä¸è¶³ç­‰é”™è¯¯
                logger.debug(f"æŸ¥è¯¢åˆ†æ”¯ '{branch_obj.name}' æ—¶å‡ºé”™: {str(e)}")
                continue
        
        # å»é‡ï¼ˆåŒä¸€ä¸ªæäº¤å¯èƒ½åœ¨å¤šä¸ªåˆ†æ”¯ä¸Šï¼‰
        seen_ids = set()
        unique_commits = []
        for commit in all_commits:
            if commit.id not in seen_ids:
                seen_ids.add(commit.id)
                unique_commits.append(commit)
        
        logger.info(f"å…±è·å–åˆ° {len(unique_commits)} æ¡æäº¤è®°å½•ï¼ˆéå†äº† {len(branches)} ä¸ªåˆ†æ”¯ï¼‰")
        return unique_commits
    
    # æ·»åŠ æ—¥æœŸèŒƒå›´
    if since_date:
        params['since'] = f"{since_date}T00:00:00Z"
    if until_date:
        params['until'] = f"{until_date}T23:59:59Z"
    
    try:
        while True:
            params['page'] = page
            page_commits = project.commits.list(**params)
            
            if not page_commits:
                break
            
            commits.extend(page_commits)
            logger.info(f"å·²è·å– {len(commits)} æ¡æäº¤è®°å½•...")
            
            # å¦‚æœè¿”å›çš„æäº¤æ•°å°‘äºæ¯é¡µæ•°é‡ï¼Œè¯´æ˜å·²ç»æ˜¯æœ€åä¸€é¡µ
            if len(page_commits) < per_page:
                break
            
            page += 1
        
        logger.info(f"å…±è·å–åˆ° {len(commits)} æ¡æäº¤è®°å½•")
        return commits
    
    except Exception as e:
        logger.error(f"è·å–æäº¤è®°å½•å¤±è´¥: {str(e)}")
        raise


def group_commits_by_date(commits):
    """
    æŒ‰æ—¥æœŸåˆ†ç»„æäº¤
    
    Args:
        commits: æäº¤åˆ—è¡¨
    
    Returns:
        dict: æŒ‰æ—¥æœŸåˆ†ç»„çš„æäº¤å­—å…¸ï¼Œæ ¼å¼ï¼š{date: [commits]}
    """
    grouped = defaultdict(list)
    
    for commit in commits:
        # è§£ææäº¤æ—¥æœŸ
        commit_date = commit.committed_date
        if isinstance(commit_date, str):
            # è§£æ ISO 8601 æ ¼å¼æ—¥æœŸ
            date_obj = datetime.fromisoformat(commit_date.replace('Z', '+00:00'))
        else:
            date_obj = commit_date
        
        # æå–æ—¥æœŸéƒ¨åˆ†ï¼ˆYYYY-MM-DDï¼‰
        date_str = date_obj.strftime('%Y-%m-%d')
        grouped[date_str].append(commit)
    
    # æŒ‰æ—¥æœŸæ’åº
    sorted_dates = sorted(grouped.keys(), reverse=True)
    return {date: grouped[date] for date in sorted_dates}


def get_all_projects(gl, owned=False, membership=False):
    """
    è·å–ç”¨æˆ·æœ‰æƒé™è®¿é—®çš„æ‰€æœ‰é¡¹ç›®
    
    Args:
        gl: GitLab å®¢æˆ·ç«¯å®ä¾‹
        owned: æ˜¯å¦åªè·å–ç”¨æˆ·æ‹¥æœ‰çš„é¡¹ç›®ï¼ˆé»˜è®¤ï¼šFalseï¼‰
        membership: æ˜¯å¦åªè·å–ç”¨æˆ·æ˜¯æˆå‘˜çš„é¡¹ç›®ï¼ˆé»˜è®¤ï¼šFalseï¼‰
    
    Returns:
        list: é¡¹ç›®åˆ—è¡¨
    """
    logger.info("å¼€å§‹è·å–æ‰€æœ‰é¡¹ç›®åˆ—è¡¨...")
    projects = []
    
    try:
        # è·å–é¡¹ç›®åˆ—è¡¨
        params = {'per_page': 100}
        if owned:
            params['owned'] = True
        if membership:
            params['membership'] = True
        
        page = 1
        while True:
            params['page'] = page
            page_projects = gl.projects.list(**params)
            
            if not page_projects:
                break
            
            projects.extend(page_projects)
            logger.info(f"å·²è·å– {len(projects)} ä¸ªé¡¹ç›®...")
            
            if len(page_projects) < 100:
                break
            
            page += 1
        
        logger.info(f"å…±è·å–åˆ° {len(projects)} ä¸ªé¡¹ç›®")
        return projects
    
    except Exception as e:
        logger.error(f"è·å–é¡¹ç›®åˆ—è¡¨å¤±è´¥: {str(e)}")
        raise


def scan_all_projects(gl, author_name, since_date=None, until_date=None, branch=None):
    """
    æ‰«ææ‰€æœ‰é¡¹ç›®ï¼ŒæŸ¥æ‰¾æŒ‡å®šæäº¤è€…çš„æäº¤
    
    Args:
        gl: GitLab å®¢æˆ·ç«¯å®ä¾‹
        author_name: æäº¤è€…å§“åæˆ–é‚®ç®±
        since_date: èµ·å§‹æ—¥æœŸï¼ˆå¯é€‰ï¼‰
        until_date: ç»“æŸæ—¥æœŸï¼ˆå¯é€‰ï¼‰
        branch: åˆ†æ”¯åç§°ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        dict: æŒ‰é¡¹ç›®åˆ†ç»„çš„æäº¤å­—å…¸ï¼Œæ ¼å¼ï¼š{project_path: {'project': project, 'commits': commits}}
    """
    logger.info(f"å¼€å§‹æ‰«ææ‰€æœ‰é¡¹ç›®ï¼ŒæŸ¥æ‰¾æäº¤è€… '{author_name}' çš„æäº¤...")
    
    # è·å–æ‰€æœ‰é¡¹ç›®
    projects = get_all_projects(gl)
    
    results = {}
    total_commits = 0
    
    for idx, project in enumerate(projects, 1):
        project_path = project.path_with_namespace
        logger.info(f"[{idx}/{len(projects)}] æ­£åœ¨æ‰«æé¡¹ç›®: {project_path}")
        
        try:
            # è·å–è¯¥é¡¹ç›®çš„æäº¤
            commits = get_commits_by_author(
                project,
                author_name,
                since_date=since_date,
                until_date=until_date,
                branch=branch
            )
            
            if commits:
                results[project_path] = {
                    'project': project,
                    'commits': commits
                }
                total_commits += len(commits)
                logger.info(f"  âœ“ æ‰¾åˆ° {len(commits)} æ¡æäº¤")
            # ä¸è¾“å‡ºæœªæ‰¾åˆ°æäº¤çš„ä¿¡æ¯ï¼Œå‡å°‘æ—¥å¿—å™ªéŸ³
        
        except Exception as e:
            # åªè®°å½•é‡è¦é”™è¯¯ï¼Œå¿½ç•¥æƒé™ä¸è¶³ç­‰å¸¸è§é”™è¯¯
            error_msg = str(e)
            if '403' in error_msg or '401' in error_msg or 'Not Found' in error_msg:
                logger.debug(f"  è·³è¿‡é¡¹ç›® {project_path}ï¼ˆæ— æƒé™æˆ–ä¸å­˜åœ¨ï¼‰")
            else:
                logger.warning(f"  æ‰«æé¡¹ç›® {project_path} æ—¶å‡ºé”™: {error_msg}")
            continue
    
    logger.info(f"æ‰«æå®Œæˆï¼Œå…±åœ¨ {len(results)} ä¸ªé¡¹ç›®ä¸­æ‰¾åˆ° {total_commits} æ¡æäº¤")
    return results


def generate_markdown_log(grouped_commits, author_name, repo_name=None):
    """
    ç”Ÿæˆ Markdown æ ¼å¼çš„æ—¥å¿—
    
    Args:
        grouped_commits: æŒ‰æ—¥æœŸåˆ†ç»„çš„æäº¤å­—å…¸
        author_name: æäº¤è€…å§“å
        repo_name: ä»“åº“åç§°ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        str: Markdown æ ¼å¼çš„æ—¥å¿—å†…å®¹
    """
    lines = []
    
    # æ ‡é¢˜
    if repo_name:
        lines.append(f"# {repo_name} - {author_name} æäº¤æ—¥å¿—\n")
    else:
        lines.append(f"# {author_name} æäº¤æ—¥å¿—\n")
    
    lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    lines.append(f"**æäº¤è€…**: {author_name}\n")
    lines.append(f"**æ€»æäº¤æ•°**: {sum(len(commits) for commits in grouped_commits.values())}\n")
    lines.append(f"**æäº¤å¤©æ•°**: {len(grouped_commits)}\n")
    lines.append("\n---\n\n")
    
    # æŒ‰æ—¥æœŸè¾“å‡ºæäº¤
    for date, commits in grouped_commits.items():
        # æ—¥æœŸæ ‡é¢˜
        date_obj = datetime.strptime(date, '%Y-%m-%d')
        date_formatted = date_obj.strftime('%Yå¹´%mæœˆ%dæ—¥')
        lines.append(f"## {date_formatted} ({date})\n")
        
        # å½“æ—¥ç»Ÿè®¡
        lines.append(f"**æäº¤æ•°**: {len(commits)}\n\n")
        
        # æäº¤åˆ—è¡¨
        for idx, commit in enumerate(commits, 1):
            # æäº¤ä¿¡æ¯
            commit_id = commit.id[:8]  # çŸ­æäº¤ ID
            commit_message = commit.message.split('\n')[0]  # ç¬¬ä¸€è¡Œæäº¤ä¿¡æ¯
            
            lines.append(f"### {idx}. [{commit_id}]({commit.web_url}) {commit_message}\n")
            
            # æäº¤æ—¶é—´
            commit_time = commit.committed_date
            if isinstance(commit_time, str):
                time_obj = datetime.fromisoformat(commit_time.replace('Z', '+00:00'))
            else:
                time_obj = commit_time
            time_str = time_obj.strftime('%H:%M:%S')
            lines.append(f"**æ—¶é—´**: {time_str}\n")
            
            # å¦‚æœæœ‰æ–‡ä»¶å˜æ›´ç»Ÿè®¡
            try:
                commit_detail = commit
                if hasattr(commit_detail, 'stats'):
                    stats = commit_detail.stats
                    if stats:
                        lines.append(f"**å˜æ›´**: +{stats.get('additions', 0)} -{stats.get('deletions', 0)}\n")
            except:
                pass
            
            lines.append("\n")
        
        lines.append("---\n\n")
    
    return ''.join(lines)


def generate_multi_project_markdown(all_results, author_name, since_date=None, until_date=None):
    """
    ç”Ÿæˆå¤šé¡¹ç›®æ±‡æ€»çš„ Markdown æ ¼å¼æ—¥å¿—
    
    Args:
        all_results: æŒ‰é¡¹ç›®åˆ†ç»„çš„æäº¤å­—å…¸
        author_name: æäº¤è€…å§“å
        since_date: èµ·å§‹æ—¥æœŸï¼ˆå¯é€‰ï¼‰
        until_date: ç»“æŸæ—¥æœŸï¼ˆå¯é€‰ï¼‰
    
    Returns:
        str: Markdown æ ¼å¼çš„æ—¥å¿—å†…å®¹
    """
    lines = []
    
    # æ ‡é¢˜
    lines.append(f"# {author_name} - æ‰€æœ‰é¡¹ç›®æäº¤æ±‡æ€»æ—¥å¿—\n")
    lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    lines.append(f"**æäº¤è€…**: {author_name}\n")
    
    # æ—¥æœŸèŒƒå›´
    if since_date and until_date:
        lines.append(f"**æ—¥æœŸèŒƒå›´**: {since_date} è‡³ {until_date}\n")
    elif since_date:
        lines.append(f"**èµ·å§‹æ—¥æœŸ**: {since_date}\n")
    elif until_date:
        lines.append(f"**ç»“æŸæ—¥æœŸ**: {until_date}\n")
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_projects = len(all_results)
    total_commits = sum(len(result['commits']) for result in all_results.values())
    
    # æŒ‰æ—¥æœŸæ±‡æ€»æ‰€æœ‰æäº¤
    all_commits_by_date = defaultdict(list)
    for project_path, result in all_results.items():
        commits = result['commits']
        for commit in commits:
            commit_date = commit.committed_date
            if isinstance(commit_date, str):
                date_obj = datetime.fromisoformat(commit_date.replace('Z', '+00:00'))
            else:
                date_obj = commit_date
            date_str = date_obj.strftime('%Y-%m-%d')
            all_commits_by_date[date_str].append({
                'project': project_path,
                'commit': commit
            })
    
    lines.append(f"**æ¶‰åŠé¡¹ç›®æ•°**: {total_projects}\n")
    lines.append(f"**æ€»æäº¤æ•°**: {total_commits}\n")
    lines.append(f"**æäº¤å¤©æ•°**: {len(all_commits_by_date)}\n")
    lines.append("\n---\n\n")
    
    # æŒ‰æ—¥æœŸè¾“å‡ºæäº¤
    sorted_dates = sorted(all_commits_by_date.keys(), reverse=True)
    for date in sorted_dates:
        date_obj = datetime.strptime(date, '%Y-%m-%d')
        date_formatted = date_obj.strftime('%Yå¹´%mæœˆ%dæ—¥')
        lines.append(f"## {date_formatted} ({date})\n")
        
        commits_on_date = all_commits_by_date[date]
        lines.append(f"**æäº¤æ•°**: {len(commits_on_date)}\n\n")
        
        # æŒ‰é¡¹ç›®åˆ†ç»„
        commits_by_project = defaultdict(list)
        for item in commits_on_date:
            commits_by_project[item['project']].append(item['commit'])
        
        # è¾“å‡ºæ¯ä¸ªé¡¹ç›®çš„æäº¤
        for project_path in sorted(commits_by_project.keys()):
            project_commits = commits_by_project[project_path]
            project_info = all_results[project_path]['project']
            
            lines.append(f"### ğŸ“¦ {project_path}\n")
            lines.append(f"**é¡¹ç›®**: [{project_info.name}]({project_info.web_url})\n")
            lines.append(f"**æäº¤æ•°**: {len(project_commits)}\n\n")
            
            # æŒ‰æ—¶é—´æ’åº
            project_commits.sort(key=lambda c: c.committed_date, reverse=True)
            
            for idx, commit in enumerate(project_commits, 1):
                commit_id = commit.id[:8]
                commit_message = commit.message.split('\n')[0]
                
                lines.append(f"#### {idx}. [{commit_id}]({commit.web_url}) {commit_message}\n")
                
                commit_time = commit.committed_date
                if isinstance(commit_time, str):
                    time_obj = datetime.fromisoformat(commit_time.replace('Z', '+00:00'))
                else:
                    time_obj = commit_time
                time_str = time_obj.strftime('%H:%M:%S')
                lines.append(f"**æ—¶é—´**: {time_str}\n\n")
            
            lines.append("---\n\n")
    
    return ''.join(lines)


def analyze_commit_type(commit_message):
    """
    åˆ†ææäº¤ç±»å‹
    
    Args:
        commit_message: æäº¤ä¿¡æ¯
    
    Returns:
        tuple: (ç±»å‹, emoji)
    """
    message_lower = commit_message.lower()
    
    # ä¼˜å…ˆæ£€æŸ¥å‰ç¼€ï¼ˆæ›´å‡†ç¡®ï¼‰
    if message_lower.startswith('fix') or message_lower.startswith('ä¿®å¤'):
        return ('Bugä¿®å¤', 'ğŸ›')
    elif message_lower.startswith('feat') or message_lower.startswith('æ–°å¢') or message_lower.startswith('æ·»åŠ '):
        return ('åŠŸèƒ½å¼€å‘', 'âœ¨')
    elif message_lower.startswith('refactor') or message_lower.startswith('é‡æ„'):
        return ('ä»£ç é‡æ„', 'â™»ï¸')
    elif message_lower.startswith('chore') or message_lower.startswith('åˆ é™¤') or message_lower.startswith('æ¸…ç†'):
        return ('ä»£ç ç»´æŠ¤', 'ğŸ”§')
    elif message_lower.startswith('docs') or message_lower.startswith('æ–‡æ¡£'):
        return ('æ–‡æ¡£æ›´æ–°', 'ğŸ“')
    elif message_lower.startswith('style') or message_lower.startswith('æ ·å¼'):
        return ('æ ·å¼è°ƒæ•´', 'ğŸ’„')
    elif message_lower.startswith('test') or message_lower.startswith('æµ‹è¯•'):
        return ('æµ‹è¯•ç›¸å…³', 'âœ…')
    # ç„¶åæ£€æŸ¥å…³é”®è¯
    elif 'ä¿®å¤' in commit_message or 'è§£å†³' in commit_message or 'bug' in message_lower:
        return ('Bugä¿®å¤', 'ğŸ›')
    elif 'æ–°å¢' in commit_message or 'æ·»åŠ ' in commit_message:
        return ('åŠŸèƒ½å¼€å‘', 'âœ¨')
    elif 'é‡æ„' in commit_message or ('ä¼˜åŒ–' in commit_message and 'ä¿®å¤' not in commit_message):
        return ('ä»£ç é‡æ„', 'â™»ï¸')
    else:
        return ('å…¶ä»–', 'ğŸ“Œ')


def generate_daily_report(all_results, author_name, since_date=None, until_date=None):
    """
    ç”Ÿæˆå¼€å‘æ—¥æŠ¥æ ¼å¼çš„ Markdown æ–‡æ¡£
    
    Args:
        all_results: æŒ‰é¡¹ç›®åˆ†ç»„çš„æäº¤å­—å…¸
        author_name: æäº¤è€…å§“å
        since_date: èµ·å§‹æ—¥æœŸï¼ˆå¯é€‰ï¼‰
        until_date: ç»“æŸæ—¥æœŸï¼ˆå¯é€‰ï¼‰
    
    Returns:
        str: Markdown æ ¼å¼çš„æ—¥æŠ¥å†…å®¹
    """
    lines = []
    
    # ç¡®å®šæ—¥æœŸ
    if since_date and until_date and since_date == until_date:
        report_date = since_date
    else:
        report_date = datetime.now().strftime('%Y-%m-%d')
    
    date_obj = datetime.strptime(report_date, '%Y-%m-%d')
    date_formatted = date_obj.strftime('%Yå¹´%mæœˆ%dæ—¥')
    
    # æ ‡é¢˜
    lines.append(f"# {author_name} - å¼€å‘æ—¥æŠ¥\n")
    lines.append(f"**æ—¥æœŸ**: {date_formatted} ({report_date})\n")
    lines.append(f"**æäº¤è€…**: {author_name}\n")
    lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    lines.append("\n---\n\n")
    
    # å·¥ä½œæ¦‚è§ˆ
    total_projects = len(all_results)
    total_commits = sum(len(result['commits']) for result in all_results.values())
    
    # æŒ‰ç±»å‹ç»Ÿè®¡
    commit_types = defaultdict(int)
    commits_by_type = defaultdict(list)
    
    # æŒ‰é¡¹ç›®å’Œæ—¶é—´ç»„ç»‡æäº¤
    project_commits = {}
    time_range = {'start': None, 'end': None}
    
    for project_path, result in all_results.items():
        project = result['project']
        commits = result['commits']
        
        project_commits[project_path] = {
            'project': project,
            'commits': [],
            'types': defaultdict(int)
        }
        
        for commit in commits:
            commit_type, emoji = analyze_commit_type(commit.message)
            commit_types[commit_type] += 1
            commits_by_type[commit_type].append({
                'project': project_path,
                'commit': commit
            })
            
            # è§£ææ—¶é—´
            commit_time = commit.committed_date
            if isinstance(commit_time, str):
                time_obj = datetime.fromisoformat(commit_time.replace('Z', '+00:00'))
            else:
                time_obj = commit_time
            
            if time_range['start'] is None or time_obj < time_range['start']:
                time_range['start'] = time_obj
            if time_range['end'] is None or time_obj > time_range['end']:
                time_range['end'] = time_obj
            
            project_commits[project_path]['commits'].append({
                'commit': commit,
                'type': commit_type,
                'emoji': emoji,
                'time': time_obj
            })
            project_commits[project_path]['types'][commit_type] += 1
        
        # æŒ‰æ—¶é—´æ’åº
        project_commits[project_path]['commits'].sort(key=lambda x: x['time'], reverse=True)
    
    # å·¥ä½œæ¦‚è§ˆ
    lines.append("## ğŸ“Š å·¥ä½œæ¦‚è§ˆ\n\n")
    lines.append(f"- **æ¶‰åŠé¡¹ç›®**: {total_projects} ä¸ª\n")
    lines.append(f"- **æ€»æäº¤æ•°**: {total_commits} æ¬¡\n")
    
    if time_range['start'] and time_range['end']:
        start_str = time_range['start'].strftime('%H:%M')
        end_str = time_range['end'].strftime('%H:%M')
        lines.append(f"- **å·¥ä½œæ—¶é—´**: {start_str} - {end_str}\n")
    
    lines.append(f"- **å·¥ä½œç±»å‹åˆ†å¸ƒ**:\n")
    for commit_type, count in sorted(commit_types.items(), key=lambda x: x[1], reverse=True):
        emoji = analyze_commit_type('')[1] if commit_type == 'å…¶ä»–' else commits_by_type[commit_type][0]['commit'].message
        type_emoji = analyze_commit_type(commits_by_type[commit_type][0]['commit'].message)[1] if commits_by_type[commit_type] else 'ğŸ“Œ'
        lines.append(f"  - {type_emoji} {commit_type}: {count} æ¬¡\n")
    
    lines.append("\n---\n\n")
    
    # æŒ‰é¡¹ç›®è¯¦ç»†å·¥ä½œå†…å®¹
    lines.append("## ğŸ“¦ å·¥ä½œè¯¦æƒ…\n\n")
    
    for project_path in sorted(project_commits.keys()):
        project_info = project_commits[project_path]
        project = project_info['project']
        commits = project_info['commits']
        
        lines.append(f"### {project.name} ({project_path})\n")
        lines.append(f"**é¡¹ç›®é“¾æ¥**: [{project.web_url}]({project.web_url})\n")
        lines.append(f"**æäº¤æ•°**: {len(commits)} æ¬¡\n")
        
        # å·¥ä½œç±»å‹ç»Ÿè®¡
        if project_info['types']:
            type_summary_parts = []
            for t, c in sorted(project_info['types'].items(), key=lambda x: x[1], reverse=True):
                # è·å–è¯¥ç±»å‹çš„ emoji
                type_emoji = analyze_commit_type('')[1]  # é»˜è®¤
                for item in commits:
                    if item['type'] == t:
                        type_emoji = item['emoji']
                        break
                type_summary_parts.append(f"{type_emoji} {t}: {c}æ¬¡")
            lines.append(f"**å·¥ä½œç±»å‹**: {', '.join(type_summary_parts)}\n")
        
        lines.append("\n**æäº¤è®°å½•**:\n\n")
        
        for idx, item in enumerate(commits, 1):
            commit = item['commit']
            commit_type = item['type']
            emoji = item['emoji']
            time_str = item['time'].strftime('%H:%M')
            
            commit_id = commit.id[:8]
            commit_message = commit.message.split('\n')[0]
            
            lines.append(f"{idx}. **{emoji} [{commit_type}]** [{commit_id}]({commit.web_url}) {commit_message}\n")
            lines.append(f"   - æ—¶é—´: {time_str}\n")
        
        lines.append("\n---\n\n")
    
    # å·¥ä½œåˆ†ç±»æ±‡æ€»
    lines.append("## ğŸ“‹ å·¥ä½œåˆ†ç±»æ±‡æ€»\n\n")
    
    for commit_type in sorted(commit_types.keys(), key=lambda x: commit_types[x], reverse=True):
        type_emoji = analyze_commit_type(commits_by_type[commit_type][0]['commit'].message)[1] if commits_by_type[commit_type] else 'ğŸ“Œ'
        lines.append(f"### {type_emoji} {commit_type} ({commit_types[commit_type]} æ¬¡)\n\n")
        
        # æŒ‰é¡¹ç›®åˆ†ç»„
        by_project = defaultdict(list)
        for item in commits_by_type[commit_type]:
            by_project[item['project']].append(item['commit'])
        
        for project_path in sorted(by_project.keys()):
            project = all_results[project_path]['project']
            commits = by_project[project_path]
            
            lines.append(f"**{project.name}** ({len(commits)} æ¬¡):\n")
            for commit in commits:
                commit_id = commit.id[:8]
                commit_message = commit.message.split('\n')[0]
                lines.append(f"- [{commit_id}]({commit.web_url}) {commit_message}\n")
            lines.append("\n")
        
        lines.append("---\n\n")
    
    # æ—¶é—´çº¿
    lines.append("## â° å·¥ä½œæ—¶é—´çº¿\n\n")
    
    all_commits_timeline = []
    for project_path, result in all_results.items():
        for commit in result['commits']:
            commit_time = commit.committed_date
            if isinstance(commit_time, str):
                time_obj = datetime.fromisoformat(commit_time.replace('Z', '+00:00'))
            else:
                time_obj = commit_time
            
            commit_type, emoji = analyze_commit_type(commit.message)
            all_commits_timeline.append({
                'time': time_obj,
                'project': project_path,
                'commit': commit,
                'type': commit_type,
                'emoji': emoji
            })
    
    all_commits_timeline.sort(key=lambda x: x['time'], reverse=True)
    
    for item in all_commits_timeline:
        time_str = item['time'].strftime('%H:%M')
        commit = item['commit']
        commit_id = commit.id[:8]
        commit_message = commit.message.split('\n')[0]
        
        lines.append(f"- **{time_str}** {item['emoji']} [{item['project']}]({all_results[item['project']]['project'].web_url}) - [{commit_id}]({commit.web_url}) {commit_message}\n")
    
    lines.append("\n---\n\n")
    
    # æ€»ç»“
    lines.append("## ğŸ“ å·¥ä½œæ€»ç»“\n\n")
    lines.append(f"ä»Šæ—¥å…±å®Œæˆ {total_commits} æ¬¡æäº¤ï¼Œæ¶‰åŠ {total_projects} ä¸ªé¡¹ç›®ã€‚")
    
    if commit_types:
        main_work = max(commit_types.items(), key=lambda x: x[1])
        lines.append(f"ä¸»è¦å·¥ä½œç±»å‹ä¸º **{main_work[0]}**ï¼ˆ{main_work[1]} æ¬¡ï¼‰ã€‚")
    
    lines.append("\n")
    
    return ''.join(lines)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='ä» GitLab ä»“åº“è·å–æäº¤è€…æ¯å¤©çš„ä»£ç æäº¤ï¼Œç”Ÿæˆ Markdown æ ¼å¼æ—¥å¿—',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºæœ¬ç”¨æ³•ï¼šæŒ‡å®šä»“åº“ã€åˆ†æ”¯ã€æäº¤è€…ï¼ˆè¾“å‡ºæ–‡ä»¶åè‡ªåŠ¨ä½¿ç”¨å½“å¤©æ—¥æœŸï¼‰
  python git2logs.py --repo http://gitlab.example.com/group/project.git --branch main --author "MIZUKI" --token YOUR_TOKEN
  
  # è·å–ä»Šå¤©çš„æäº¤ï¼ˆè‡ªåŠ¨ä½¿ç”¨ä»Šå¤©æ—¥æœŸä½œä¸ºæ–‡ä»¶åå‰ç¼€ï¼‰
  python git2logs.py --repo http://gitlab.example.com/group/project.git --branch develop --author "MIZUKI" --today --token YOUR_TOKEN
  
  # è‡ªåŠ¨æ‰«ææ‰€æœ‰é¡¹ç›®ï¼ŒæŸ¥æ‰¾æŒ‡å®šæäº¤è€…ä»Šå¤©çš„æäº¤
  python git2logs.py --scan-all --gitlab-url http://gitlab.example.com --author "MIZUKI" --today --token YOUR_TOKEN
  
  # è‡ªåŠ¨æ‰«ææ‰€æœ‰é¡¹ç›®ï¼ŒæŒ‡å®šåˆ†æ”¯å’Œæ—¥æœŸèŒƒå›´
  python git2logs.py --scan-all --gitlab-url http://gitlab.example.com --branch master --author "MIZUKI" --since 2024-01-01 --until 2024-12-31 --token YOUR_TOKEN
  
  # æ‰‹åŠ¨æŒ‡å®šè¾“å‡ºæ–‡ä»¶
  python git2logs.py --repo group/project --branch main --author "John Doe" --output commits.md
        """
    )
    
    parser.add_argument(
        '--repo',
        help='GitLab ä»“åº“åœ°å€æˆ–è·¯å¾„ï¼ˆä¾‹å¦‚ï¼šhttps://gitlab.com/group/project æˆ– group/projectï¼‰ã€‚å¦‚æœä½¿ç”¨ --scan-allï¼Œåˆ™ä¸éœ€è¦æ­¤å‚æ•°'
    )
    
    parser.add_argument(
        '--author',
        required=True,
        help='æäº¤è€…å§“åæˆ–é‚®ç®±'
    )
    
    parser.add_argument(
        '--scan-all',
        action='store_true',
        help='è‡ªåŠ¨æ‰«ææ‰€æœ‰æœ‰æƒé™è®¿é—®çš„é¡¹ç›®ï¼ŒæŸ¥æ‰¾æŒ‡å®šæäº¤è€…çš„æäº¤ï¼ˆéœ€è¦æä¾› GitLab URL å’Œè®¿é—®ä»¤ç‰Œï¼‰'
    )
    
    parser.add_argument(
        '--token',
        help='GitLab è®¿é—®ä»¤ç‰Œï¼ˆç§æœ‰ä»“åº“éœ€è¦ï¼Œä¹Ÿå¯é€šè¿‡ç¯å¢ƒå˜é‡ GITLAB_TOKEN è®¾ç½®ï¼‰'
    )
    
    parser.add_argument(
        '--gitlab-url',
        default='https://gitlab.com',
        help='GitLab å®ä¾‹ URLï¼ˆé»˜è®¤ï¼šhttps://gitlab.comï¼‰'
    )
    
    parser.add_argument(
        '--since',
        help='èµ·å§‹æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰'
    )
    
    parser.add_argument(
        '--until',
        help='ç»“æŸæ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰'
    )
    
    parser.add_argument(
        '--branch',
        help='æŒ‡å®šåˆ†æ”¯åç§°ï¼ˆé»˜è®¤æŸ¥è¯¢æ‰€æœ‰åˆ†æ”¯ï¼‰'
    )
    
    parser.add_argument(
        '--today',
        action='store_true',
        help='ä»…è·å–ä»Šå¤©çš„æäº¤ï¼ˆè‡ªåŠ¨è®¾ç½®æ—¥æœŸèŒƒå›´ä¸ºä»Šå¤©ï¼‰'
    )
    
    parser.add_argument(
        '--output',
        '-o',
        help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šä½¿ç”¨å½“å¤©æ—¥æœŸä½œä¸ºæ–‡ä»¶åå‰ç¼€ï¼Œæ ¼å¼ï¼šYYYY-MM-DD_commits.mdï¼‰'
    )
    
    parser.add_argument(
        '--daily-report',
        action='store_true',
        help='ç”Ÿæˆå¼€å‘æ—¥æŠ¥æ ¼å¼ï¼ˆæ›´è¯¦ç»†çš„å·¥ä½œåˆ†æå’Œåˆ†ç±»ï¼‰'
    )
    
    args = parser.parse_args()
    
    # éªŒè¯å‚æ•°
    if args.scan_all and args.repo:
        logger.error("--scan-all å’Œ --repo ä¸èƒ½åŒæ—¶ä½¿ç”¨")
        sys.exit(1)
    
    if not args.scan_all and not args.repo:
        logger.error("å¿…é¡»æä¾› --repo æˆ–ä½¿ç”¨ --scan-all")
        sys.exit(1)
    
    # å¦‚æœæŒ‡å®šäº† --todayï¼Œè‡ªåŠ¨è®¾ç½®æ—¥æœŸèŒƒå›´ä¸ºä»Šå¤©
    if args.today:
        today = datetime.now().strftime('%Y-%m-%d')
        args.since = today
        args.until = today
        logger.info(f"å·²è®¾ç½®æ—¥æœŸèŒƒå›´ä¸ºä»Šå¤©: {today}")
    
    try:
        # è·å–è®¿é—®ä»¤ç‰Œï¼ˆä¼˜å…ˆä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ï¼Œå…¶æ¬¡ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰
        token = args.token or None
        if not token:
            token = os.environ.get('GITLAB_TOKEN')
        
        if not token:
            logger.error("å¿…é¡»æä¾›è®¿é—®ä»¤ç‰Œï¼ˆ--token æˆ–ç¯å¢ƒå˜é‡ GITLAB_TOKENï¼‰")
            sys.exit(1)
        
        # ç¡®å®š GitLab URL
        gitlab_url = args.gitlab_url
        
        if args.scan_all:
            # æ‰«ææ‰€æœ‰é¡¹ç›®æ¨¡å¼
            if not gitlab_url or gitlab_url == 'https://gitlab.com':
                logger.error("ä½¿ç”¨ --scan-all æ—¶å¿…é¡»æŒ‡å®š --gitlab-url")
                sys.exit(1)
            
            logger.info(f"ä½¿ç”¨è‡ªåŠ¨æ‰«ææ¨¡å¼ï¼ŒGitLab å®ä¾‹: {gitlab_url}")
            
            # åˆ›å»º GitLab å®¢æˆ·ç«¯
            gl = create_gitlab_client(gitlab_url, token)
            
            # æ‰«ææ‰€æœ‰é¡¹ç›®
            all_results = scan_all_projects(
                gl,
                args.author,
                since_date=args.since,
                until_date=args.until,
                branch=args.branch
            )
            
            if not all_results:
                logger.warning(f"æœªåœ¨ä»»ä½•é¡¹ç›®ä¸­æ‰¾åˆ°æäº¤è€… '{args.author}' çš„æäº¤è®°å½•")
                sys.exit(0)
            
            # ç”Ÿæˆ Markdown æ—¥å¿—
            if args.daily_report:
                markdown_content = generate_daily_report(
                    all_results,
                    args.author,
                    since_date=args.since,
                    until_date=args.until
                )
                # ç¡®å®šè¾“å‡ºæ–‡ä»¶å
                if args.output:
                    output_file = args.output
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®å½•ï¼Œå¦‚æœæ˜¯ç›®å½•åˆ™è‡ªåŠ¨ç”Ÿæˆæ–‡ä»¶å
                    if os.path.isdir(output_file):
                        today = datetime.now().strftime('%Y-%m-%d')
                        branch_suffix = f"_{args.branch}" if args.branch else ""
                        filename = f"{today}_daily_report{branch_suffix}.md"
                        output_file = os.path.join(output_file, filename)
                        logger.info(f"è¾“å‡ºè·¯å¾„æ˜¯ç›®å½•ï¼Œè‡ªåŠ¨ç”Ÿæˆæ–‡ä»¶å: {output_file}")
                    # å¦‚æœè¾“å‡ºæ–‡ä»¶æ²¡æœ‰æ‰©å±•åï¼Œè‡ªåŠ¨æ·»åŠ  .md
                    elif not os.path.splitext(output_file)[1]:
                        output_file = output_file + '.md'
                        logger.info(f"è¾“å‡ºæ–‡ä»¶æ— æ‰©å±•åï¼Œè‡ªåŠ¨æ·»åŠ  .md: {output_file}")
                else:
                    today = datetime.now().strftime('%Y-%m-%d')
                    branch_suffix = f"_{args.branch}" if args.branch else ""
                    output_file = f"{today}_daily_report{branch_suffix}.md"
            else:
                markdown_content = generate_multi_project_markdown(
                    all_results,
                    args.author,
                    since_date=args.since,
                    until_date=args.until
                )
                # ç¡®å®šè¾“å‡ºæ–‡ä»¶å
                if args.output:
                    output_file = args.output
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®å½•ï¼Œå¦‚æœæ˜¯ç›®å½•åˆ™è‡ªåŠ¨ç”Ÿæˆæ–‡ä»¶å
                    if os.path.isdir(output_file):
                        today = datetime.now().strftime('%Y-%m-%d')
                        branch_suffix = f"_{args.branch}" if args.branch else ""
                        filename = f"{today}_all_projects{branch_suffix}.md"
                        output_file = os.path.join(output_file, filename)
                        logger.info(f"è¾“å‡ºè·¯å¾„æ˜¯ç›®å½•ï¼Œè‡ªåŠ¨ç”Ÿæˆæ–‡ä»¶å: {output_file}")
                    # å¦‚æœè¾“å‡ºæ–‡ä»¶æ²¡æœ‰æ‰©å±•åï¼Œè‡ªåŠ¨æ·»åŠ  .md
                    elif not os.path.splitext(output_file)[1]:
                        output_file = output_file + '.md'
                        logger.info(f"è¾“å‡ºæ–‡ä»¶æ— æ‰©å±•åï¼Œè‡ªåŠ¨æ·»åŠ  .md: {output_file}")
                else:
                    today = datetime.now().strftime('%Y-%m-%d')
                    branch_suffix = f"_{args.branch}" if args.branch else ""
                    output_file = f"{today}_all_projects{branch_suffix}.md"
        
        else:
            # å•é¡¹ç›®æ¨¡å¼
            # å¦‚æœä»“åº“ URL æ˜¯å®Œæ•´ URLï¼Œå°è¯•ä»ä¸­æå– GitLab URL
            extracted_url = extract_gitlab_url(args.repo)
            if extracted_url:
                gitlab_url = extracted_url
                logger.info(f"ä»ä»“åº“ URL æå– GitLab å®ä¾‹: {gitlab_url}")
            
            # åˆ›å»º GitLab å®¢æˆ·ç«¯
            gl = create_gitlab_client(gitlab_url, token)
            
            # è§£æé¡¹ç›®æ ‡è¯†ç¬¦
            project_id = parse_project_identifier(args.repo)
            logger.info(f"é¡¹ç›®æ ‡è¯†ç¬¦: {project_id}")
            
            # è·å–é¡¹ç›®
            try:
                project = gl.projects.get(project_id)
                logger.info(f"æˆåŠŸè·å–é¡¹ç›®: {project.name}")
            except Exception as e:
                logger.error(f"è·å–é¡¹ç›®å¤±è´¥: {str(e)}")
                logger.error("è¯·æ£€æŸ¥é¡¹ç›®è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œä»¥åŠæ˜¯å¦æœ‰è®¿é—®æƒé™")
                sys.exit(1)
            
            # è·å–æäº¤è®°å½•
            commits = get_commits_by_author(
                project,
                args.author,
                since_date=args.since,
                until_date=args.until,
                branch=args.branch
            )
            
            if not commits:
                logger.warning(f"æœªæ‰¾åˆ°æäº¤è€… '{args.author}' çš„æäº¤è®°å½•")
                sys.exit(0)
            
            # æŒ‰æ—¥æœŸåˆ†ç»„
            grouped_commits = group_commits_by_date(commits)
            
            # ç”Ÿæˆ Markdown æ—¥å¿—
            markdown_content = generate_markdown_log(
                grouped_commits,
                args.author,
                repo_name=project.name
            )
            
            # ç¡®å®šè¾“å‡ºæ–‡ä»¶å
            if args.output:
                output_file = args.output
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®å½•ï¼Œå¦‚æœæ˜¯ç›®å½•åˆ™è‡ªåŠ¨ç”Ÿæˆæ–‡ä»¶å
                if os.path.isdir(output_file):
                    today = datetime.now().strftime('%Y-%m-%d')
                    branch_suffix = f"_{args.branch}" if args.branch else ""
                    if args.daily_report:
                        filename = f"{today}_daily_report{branch_suffix}.md"
                    else:
                        filename = f"{today}_all_projects{branch_suffix}.md"
                    output_file = os.path.join(output_file, filename)
                    logger.info(f"è¾“å‡ºè·¯å¾„æ˜¯ç›®å½•ï¼Œè‡ªåŠ¨ç”Ÿæˆæ–‡ä»¶å: {output_file}")
                # å¦‚æœè¾“å‡ºæ–‡ä»¶æ²¡æœ‰æ‰©å±•åï¼Œè‡ªåŠ¨æ·»åŠ  .md
                elif not os.path.splitext(output_file)[1]:
                    output_file = output_file + '.md'
                    logger.info(f"è¾“å‡ºæ–‡ä»¶æ— æ‰©å±•åï¼Œè‡ªåŠ¨æ·»åŠ  .md: {output_file}")
            else:
                # å¦‚æœæœªæŒ‡å®šè¾“å‡ºæ–‡ä»¶ï¼Œä½¿ç”¨å½“å¤©æ—¥æœŸä½œä¸ºæ–‡ä»¶åå‰ç¼€
                today = datetime.now().strftime('%Y-%m-%d')
                branch_suffix = f"_{args.branch}" if args.branch else ""
                output_file = f"{today}_commits{branch_suffix}.md"
        
        # è¾“å‡ºç»“æœ
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        logger.info(f"æ—¥å¿—å·²ä¿å­˜åˆ°: {output_file}")
    
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")
        sys.exit(1)


if __name__ == '__main__':
    main()
